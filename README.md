# Fruit Classifier Web Application

## Project Structure

```
fruit_classifier/
├── assets/
│   ├── apple.png
│   ├── banana.png
│   └── grape.png
├── model_training.py
├── app.py
├── fruit_data.csv
├── fruit_pipeline.joblib  # Generated after running model_training.py
└── requirements.txt
```

-   `assets/`: Contains image files for the fruits (apple, banana, grape) used in the Streamlit app.
-   `model_training.py`: Python script responsible for loading data, preprocessing, training the machine learning model, and saving the trained pipeline.
-   `app.py`: The main Streamlit application script, which loads the trained model and provides the interactive user interface.
-   `fruit_data.csv`: The dataset used for training the fruit classification model.
-   `fruit_pipeline.joblib`: The trained machine learning model (a scikit-learn pipeline) saved as a joblib file. This is generated by `model_training.py`.
-   `requirements.txt`: Lists all Python libraries required to run the project.

## Setup and Installation

Follow these steps to get the project up and running on your local machine.

### Prerequisites

-   Python 3.8+ installed.
    (If you need to update Python, please download the latest installer from [python.org/downloads/](https://www.python.org/downloads/) and ensure "Add Python X.X to PATH" is checked during installation.)

### Steps

1.  **Clone the Repository (or download the files):**
    If this were a Git repository, you'd clone it. For this project, ensure all files (`model_training.py`, `app.py`, `requirements.txt`, `fruit_data.csv`, and the `assets` folder with images) are in a single directory.

2.  **Navigate to the Project Directory:**
    Open your Command Prompt (`cmd.exe`) and change to the project's root directory:
    ```cmd
    cd C:\Path\To\Your\fruit_classifier
    ```
    (Replace `C:\Path\To\Your\fruit_classifier` with the actual path where you saved the project files.)

3.  **Create a Virtual Environment:**
    It's good practice to use a virtual environment to manage project dependencies.
    ```cmd
    python -m venv venv
    ```

4.  **Activate the Virtual Environment:**
    ```cmd
    .\venv\Scripts\activate
    ```
    You should see `(venv)` at the beginning of your command prompt, indicating the environment is active.

5.  **Install Required Libraries:**
    Install all the necessary Python packages using `pip`.
    ```cmd
    pip install -r requirements.txt
    ```

## How to Run

After completing the setup and installation:

1.  **Train the Machine Learning Model:**
    This step generates the `fruit_pipeline.joblib` file, which the web application uses for predictions.
    ```cmd
    python model_training.py
    ```
    You should see output indicating data loading, cleaning, model training, and saving of the pipeline.

2.  **Start the Streamlit Web Application:**
    ```cmd
    streamlit run app.py
    ```
    Your default web browser will automatically open a new tab with the Fruit Classifier application. If it doesn't, copy the `Network URL` displayed in your command prompt (e.g., `http://localhost:8501`) and paste it into your browser.

## Data (`fruit_data.csv`)

The dataset `fruit_data.csv` contains the following columns:

-   `color`: Categorical (e.g., 'Yellow', 'Red', 'Green')
-   `size`: Categorical ordinal (e.g., 'Tiny', 'Small', 'Medium', 'Large')
-   `weight`: Numerical (e.g., '80', '150')
-   `fruit_type`: Target variable, Categorical (e.g., 'banana', 'apple', 'grape')

**Data Cleaning:**
During preprocessing, a known typo `'Largee'` in the `size` column is corrected to `'Large'` to ensure consistent data.

## Model Details

-   **Model Type**: `scikit-learn` Pipeline with `ColumnTransformer` and `RandomForestClassifier`.
-   **Preprocessing**:
    -   `color`: One-Hot Encoded (nominal categorical feature).
    -   `size`: Ordinally Encoded (ordinal categorical feature with explicit order: ['Tiny', 'Small', 'Medium', 'Large']).
    -   `weight`: Passed through without transformation (numerical feature).
-   **Classifier**: `RandomForestClassifier` with 100 estimators and `random_state=42` for reproducibility.

---

## Project Evaluation: A Reflection on My Work

Here’s a quick look back at how I approached this project, touching on the key evaluation points.

### 1. Getting the Data Ready
Right away, I noticed the dataset was mostly clean, but I did find a small typo (`'Largee'`) in the `size` column. I wrote a quick line of code in the `model_training.py` script to fix that across the board. This was a good reminder that even simple datasets need a quick check for errors. Since there weren't any missing values, I could move straight to getting the features ready for the model. The whole process is laid out step-by-step in the training script, so it's easy to see exactly how the raw data gets transformed.

### 2. Choosing and Building the Model
I decided to use a `RandomForestClassifier`. It's built from decision trees, which fits the project requirements, and it's generally a strong performer right out of the box. Instead of getting lost in tuning lots of settings, I set some simple, transparent hyperparameters (`n_estimators=100` and `random_state=42`). This made the model's behaviour predictable and ensured that anyone running the training script would get the exact same result I did.

### 3. Checking if the Model Works
To make sure the model wasn't just memorizing the data, I split it into a training set and a testing set. The model only ever saw the training data, and I used the testing data to get an honest grade on its performance. I focused on accuracy as the main metric because it’s a straightforward way to see how often the model gets the prediction right. In the app itself, I also added a "confidence score" to show the user how sure the model is about its prediction, which I thought was a nice touch for interpretation.

### 4. Documenting the Project
From the start, I wanted to make this project easy for anyone to understand and run. I commented the code in both `model_training.py` and `app.py` to explain my thinking. This `README` file acts as the main guide, covering everything from the project structure to a step-by-step on how to run it. Finally, the Streamlit app itself is a live demonstration of the results, making it clear what the project accomplishes.

This section evaluates the "Fruit Classifier Web Application" project against the specified criteria, detailing the methodologies, decisions, and outcomes related to data handling, modeling, performance, and communication.